<!doctype html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>ollama 运行 DeepSeek 模型</title>
  <link rel="stylesheet" href="../../static/style.css" />
  <link rel="icon" href="../../static/favicon.svg" type="image/svg+xml" />
  <meta name="color-scheme" content="light dark" />
  
  <!-- MathJax Configuration -->
  <script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true,
        tags: 'ams'
      },
      options: {
        ignoreHtmlClass: 'tex2jax_ignore',
        processHtmlClass: 'tex2jax_process'
      },
      svg: {
        fontCache: 'global'
      }
    };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
  </script>
</head>
<body>
  <header class="site-header">
    <div class="container header-inner">
      <a class="brand" href="../../index.html">My Blog</a>
  <button class="menu-toggle" id="menuToggle" aria-label="打开菜单" aria-controls="primaryNav" aria-expanded="false">☰</button>
  <nav class="nav" id="primaryNav">
        <a class="nav-link" href="../../index.html">首页</a>
        <a class="nav-link" href="../../categories.html">Categories</a>
        <a class="nav-link" href="../../tags.html">Tags</a>
        <a class="nav-link github" href="https://github.com/wardenxyz" target="_blank" rel="noopener">GitHub</a>
      </nav>
    </div>
  </header>

  <main class="container layout layout-3">
    <aside class="sidebar-col" id="sidebar">
      <nav class="sidebar" aria-label="所有文章"><div class="sidebar-group"><div class="sidebar-year">Others</div><ul><li><a href="../../index.html">随便写写</a></li><li><a href="../../categories.html">Categories</a></li><li><a href="../../tags.html">Tags</a></li></ul></div><div class="sidebar-group"><div class="sidebar-year">2025</div><ul><li><a href="SOPS.html">SOPS:Secrets OPerationS</a></li><li><a href="age.html">age-note</a></li><li><a href="yt-dlp.html">yt-dlp 使用</a></li><li><a href="cross-platform-byte-control.md.html">跨系统避免换行符导致字节差异的方法</a></li><li><a href="introduce-passkey.html">Passkey:Secure,Convenient Login</a></li><li><a href="npm-config.html">修改 npm node_modules 位置</a></li><li><a href="powershell-get-command.html">PowerShell Get-Command 命令</a></li><li><a href="background-color.html">背景颜色</a></li><li><a href="git-hook.html">自用 git hook</a></li><li><a href="typst-syntax-simple-introduction.html">Typst 语法简单介绍</a></li><li><a href="shut-wps-background-runing.html">关闭 WPS 后台运行</a></li><li><a href="font.html">个人字体</a></li><li><a href="github-avatar.html">GitHub 头像</a></li><li><a href="regex-note.html">正则表达式简明指南</a></li><li><a href="Rollback-commit.html">回滚提交</a></li><li><a href="use_python_gen_site.html">使用 Python 生成静态网页</a></li><li><a href="install_wsl2_and_to_d_disk.html">安装 WSL2 并迁移到 D 盘</a></li><li><a href="zed_use_typstyle.html">在 zed 上配置 typstyle</a></li><li><a href="Rust_Windows_Config.html">在 Windows 上配置 Rust 环境</a></li><li><a href="conda_note.html">conda 使用笔记</a></li><li><a href="Zed_set_OpenAI_API_Compatible_model.html">在 Zed Editor 中配置 OpenAI API 兼容的模型</a></li><li><a href="zed_use.html">zed 使用笔记</a></li><li><a href="ollama_run_deepseek.html" class="active">ollama 运行 DeepSeek 模型</a></li></ul></div><div class="sidebar-group"><div class="sidebar-year">2024</div><ul><li><a href="../2024/pull_request_steps.html">Pull Request 的步骤</a></li><li><a href="../2024/Typst_note.html">Typst 笔记</a></li><li><a href="../2024/git_reset.html">git 重置当前分支</a></li><li><a href="../2024/vitepress_note.html">vitepress 学习笔记</a></li><li><a href="../2024/deploy_gitHub_page.html">GitHub page 搭建学习笔记</a></li><li><a href="../2024/Linux_note.html">Linux 学习笔记</a></li><li><a href="../2024/OpenSSL_encrypt_note.html">OpenSSL 加解密速查笔记</a></li><li><a href="../2024/python_note.html">python 学习笔记</a></li><li><a href="../2024/lazy.nvim_note.html">lazy.nvim 学习笔记</a></li><li><a href="../2024/git-izer_note.html">git-sizer 学习笔记</a></li><li><a href="../2024/git_force_overwrite_local_repo.html">git 强制覆盖本地仓库</a></li><li><a href="../2024/bilibili_embedding_code.html">B站嵌入代码</a></li><li><a href="../2024/personal_software.html">个人自用软件</a></li><li><a href="../2024/you-get_note.html">用 you-get 下载B站视频</a></li><li><a href="../2024/git-crypt_note.html">git-crypt 学习笔记</a></li><li><a href="../2024/gen_GPG_key.html">生成 GPG 密钥</a></li><li><a href="../2024/git-crypt_official_doc.html">git-crypt 官方文档</a></li><li><a href="../2024/git-crypt_official_doc_zh.html">git-crypt 官方文档中文翻译</a></li><li><a href="../2024/README_outline.html">README 文档结构</a></li><li><a href="../2024/git_commit_message_standard.html">git commit message 规范</a></li><li><a href="../2024/vscode_snippets_variable.html">vscode snippets 预置变量</a></li><li><a href="../2024/modern_cryptography.html">现代加密学</a></li><li><a href="../2024/former_doctor_who.html">神秘博士复活时间表</a></li><li><a href="../2024/ffmpeg_note.html">ffmpeg 自用命令</a></li><li><a href="../2024/qqmail_third_party_config.html">第三方邮箱客户端配置QQmail & Foxmail</a></li><li><a href="../2024/git_Cli.html">git 命令手册</a></li><li><a href="../2024/LaTeX_note.html">LaTeX 与希腊字母对照表</a></li><li><a href="../2024/git_branch.html">git 分支操作</a></li><li><a href="../2024/remove_file_from_git_history.html">从 git 提交中移除文件</a></li><li><a href="../2024/vim_note.html">Vim 高效速查笔记</a></li><li><a href="../2024/obsidian_shortcut_key.html">obsidian快捷键</a></li><li><a href="../2024/android_QQ_file_storage_path.html">手机QQ文件存储路径</a></li><li><a href="../2024/browser_UA_value.html">浏览器UA值</a></li><li><a href="../2024/gpg_communication.html">GPG 在通信中的简单理解</a></li><li><a href="../2024/vscode_note.html">VSCode 高效使用指南</a></li></ul></div></nav>
    </aside>
    <article class="content" id="content">
      <h1 id="ollama-deepseek">ollama 运行 DeepSeek 模型</h1>
<p>最近 DeepSeek-R1 开源，风头无两，用 o1 几十分之一的成本训练出一个比肩 o1 的模型，而且还开源，不仅把模型开源，还把训练方法开源，而且还是 MIT 协议，随意商用</p>
<p>除此之外，DeepSeek 还用 R1 的蒸馏数据训练了其它几个火爆的开源模型：Qwen、Llama，推出了 <code>DeepSeek-R1-Distill-Llama</code> 和 <code>DeepSeek-R1-Distill-Qwen</code>，其中 <code>DeepSeek-R1-Distill-Qwen</code> 有 1.5B 版本</p>
<p>然后看网上有人说 1.5B 的小模型可以在任何设备上运行，我就心痒痒了，想在我的小破电脑上玩一下这个模型</p>
<p>我的电脑配置</p>
<ul>
<li>12th Gen Intel(R) Core(TM) i5-12500H</li>
<li>16 GB内存</li>
</ul>
<h2 id="_1">步骤</h2>
<h3 id="1-ollama">1. 下载 ollama</h3>
<p>https://ollama.com/download</p>
<p>Windows 下载好后要把 ollama 加入到环境变量中</p>
<h3 id="2">2. 下载模型</h3>
<p>在魔搭社区找到<a href="https://www.modelscope.cn/collections/DeepSeek-R1-Distill-GGUF-eec5fee2f2ee42">这个网页</a>，找到 <code>DeepSeek-R1-Distill-Qwen-1.5B</code>，下载模型：</p>
<pre><code class="language-bash">git clone https://www.modelscope.cn/unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF.git
</code></pre>
<h3 id="3-modelfile">3. 创建 Modelfile 文件</h3>
<p>进入 DeepSeek-R1-Distill-Qwen-1.5B-GGUF 文件夹</p>
<pre><code class="language-bash">cd DeepSeek-R1-Distill-Qwen-1.5B-GGUF
</code></pre>
<p>创建 Modelfile 文件，在 Modelfile 中写入 GGUF 的路径：</p>
<pre><code class="language-Modelfile">FROM D:\workspace\R1-Qwen\DeepSeek-R1-Distill-Qwen-1.5B-GGUF\DeepSeek-R1-Distill-Qwen-1.5B-Q2_K.gguf
</code></pre>
<h3 id="4-ollama">4. 把本地模型加入到 ollama 中</h3>
<pre><code class="language-bash">ollama create DeepSeek-R1-Distill-Qwen-1.5B
</code></pre>
<p>成功会报：</p>
<pre><code class="language-bash">gathering model components
copying file sha256:e18142b69b2dbdac59eca6bf77dde2054078003bcb9534e02e7ca1cf26eb5675 100%
parsing GGUF
using existing layer sha256:e18142b69b2dbdac59eca6bf77dde2054078003bcb9534e02e7ca1cf26eb5675
writing manifest
success
</code></pre>
<p>查看模型：</p>
<pre><code class="language-bash">ollama list
</code></pre>
<p>报：</p>
<pre><code class="language-bash">NAME                                    ID              SIZE      MODIFIED
DeepSeek-R1-Distill-Qwen-1.5B:latest    3c5f0a638147    752 MB    2 minutes ago
</code></pre>
<h3 id="5">5. 运行</h3>
<pre><code class="language-bash">ollama run DeepSeek-R1-Distill-Qwen-1.5B:latest
</code></pre>
<p>就可以在终端里对话了</p>
<h2 id="_2">命令汇总</h2>
<pre><code class="language-bash">git clone https://www.modelscope.cn/unsloth/DeepSeek-R1-Distill-Qwen-1.5B-GGUF.git
</code></pre>
<pre><code class="language-bash">cd DeepSeek-R1-Distill-Qwen-1.5B-GGUF
</code></pre>
<p>创建 Modelfile，并把 GGUP 的路径写入</p>
<pre><code class="language-bash">ollama create DeepSeek-R1-Distill-Qwen-1.5B
</code></pre>
<pre><code class="language-bash">ollama create DeepSeek-R1-Distill-Qwen-1.5B
</code></pre>
<pre><code class="language-bash">ollama run DeepSeek-R1-Distill-Qwen-1.5B:latest
</code></pre>
<h2 id="_3">感受</h2>
<p>ollama 很简单，很易用</p>
<p>1.5B 的小模型会胡言乱语</p>
<p>模型运行时会吃满 CPU 和内存，不能再打开第二个软件了，打开会卡死</p>
    </article>
    <aside class="toc" id="toc">
      <div class="toc-title">大纲</div>
      <div class="toc">
<ul>
<li><a href="#ollama-deepseek">ollama 运行 DeepSeek 模型</a><ul>
<li><a href="#_1">步骤</a><ul>
<li><a href="#1-ollama">1. 下载 ollama</a></li>
<li><a href="#2">2. 下载模型</a></li>
<li><a href="#3-modelfile">3. 创建 Modelfile 文件</a></li>
<li><a href="#4-ollama">4. 把本地模型加入到 ollama 中</a></li>
<li><a href="#5">5. 运行</a></li>
</ul>
</li>
<li><a href="#_2">命令汇总</a></li>
<li><a href="#_3">感受</a></li>
</ul>
</li>
</ul>
</div>

    </aside>
  </main>

  <footer class="site-footer">
    <div class="container" style="text-align: center;">
      <div>© 2024 - 2025 wardenxyz</div>
      <div>MIT License</div>
    </div>
  </footer>

  <button id="backToTop" class="back-to-top" aria-label="回到顶部">↑</button>

  <script src="../../static/main.js"></script>
</body>
</html>
